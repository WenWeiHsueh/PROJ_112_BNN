{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh0Inqmad5Y-",
        "outputId": "1eda02f9-cc2d-4d98-f68d-6e53ceb9e1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1 (BinaryConv2D)        (None, 32, 28, 28)        288       \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 16, 14, 28)        0         \n",
            "                                                                 \n",
            " bn2 (BatchNormalization)    (None, 16, 14, 28)        64        \n",
            "                                                                 \n",
            " act2 (Activation)           (None, 16, 14, 28)        0         \n",
            "                                                                 \n",
            " act1 (Activation)           (None, 16, 14, 28)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                200736    \n",
            "                                                                 \n",
            " bn5 (BatchNormalization)    (None, 32)                128       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201,546\n",
            "Trainable params: 201,450\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1200/1200 [==============================] - 57s 47ms/step - loss: 0.9407 - accuracy: 0.9269 - val_loss: 0.9225 - val_accuracy: 0.9498\n",
            "Test score: 0.9224636554718018\n",
            "Test accuracy: 0.9498000144958496\n"
          ]
        }
      ],
      "source": [
        "'''Trains a simple binarize CNN on the MNIST dataset.\n",
        "Modified from keras' examples/mnist_mlp.py\n",
        "Gets to 98.98% test accuracy after 20 epochs using tensorflow backend\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.utils import np_utils\n",
        "from keras import callbacks\n",
        "from binary_ops import binary_tanh as binary_tanh_op\n",
        "from binary_layers import BinaryDense, BinaryConv2D\n",
        "from binary_ops import binarize\n",
        "from keras import callbacks\n",
        "def binary_tanh(x):\n",
        "    return binary_tanh_op(x)\n",
        "\n",
        "\n",
        "H = 1.\n",
        "kernel_lr_multiplier = 'Glorot'\n",
        "\n",
        "# nn\n",
        "batch_size = 50\n",
        "epochs = 20 \n",
        "channels = 1\n",
        "img_rows = 28 \n",
        "img_cols = 28 \n",
        "filters = 32 \n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2, 2)\n",
        "hidden_units = 128\n",
        "classes = 10\n",
        "use_bias = False\n",
        "#############################基本設定#############################\n",
        "# learning rate schedule\n",
        "lr_start = 1e-3\n",
        "lr_end = 1e-4\n",
        "lr_decay = (lr_end / lr_start)**(1. / epochs)\n",
        "\n",
        "# BN\n",
        "epsilon = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "# dropout\n",
        "p1 = 0.25\n",
        "p2 = 0.5\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 1, 28, 28) ####調整資料大小\n",
        "X_test = X_test.reshape(10000, 1, 28, 28)   ##調整資料大小\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255    ##正規化\n",
        "X_test /= 255     ##正規化\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, classes) * 2 - 1 # -1 or 1 for hinge loss\n",
        "Y_test = np_utils.to_categorical(y_test, classes) * 2 - 1\n",
        "\n",
        "model = Sequential()\n",
        "# conv1\n",
        "model.add(BinaryConv2D(32, kernel_size=kernel_size, input_shape=(channels, img_rows, img_cols),\n",
        "                       data_format='channels_first',\n",
        "                       H=H, kernel_lr_multiplier=kernel_lr_multiplier, \n",
        "                       padding='same', use_bias=use_bias, name='conv1'))\n",
        "# model.add(BinaryConv2D(32, kernel_size=kernel_size, H=H, kernel_lr_multiplier=kernel_lr_multiplier,                         \n",
        "#                        data_format='channels_first',\n",
        "#                        padding='same', use_bias=use_bias, name='conv2'))\n",
        "# model.add(BinaryConv2D(32, kernel_size=kernel_size, H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
        "#                        data_format='channels_first',\n",
        "#                        padding='same', use_bias=use_bias, name='conv3'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, name='pool2', data_format='channels_last'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn2'))\n",
        "model.add(Activation(binary_tanh, name='act2'))\n",
        "#model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn1'))\n",
        "model.add(Activation(binary_tanh, name='act1'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn5'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "opt = Adam(lr=lr_start) \n",
        "model.compile(loss='squared_hinge', optimizer=opt, metrics=['accuracy'])\n",
        "model.summary()\n",
        "lr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay ** e)\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=50, epochs=1,\n",
        "                    verbose=1, validation_data=(X_test, Y_test))\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "# print(model.layers[0].get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vOKdLENTgza-"
      },
      "outputs": [],
      "source": [
        "binary_kernel_1 = binarize(model.layers[0].kernel, H=model.layers[0].H) \n",
        "# binary_kernel_2 = binarize(model.layers[1].kernel, H=model.layers[1].H) # 成功率若不夠再加\n",
        "# # binary_kernel_3 = binarize(model.layers[2].kernel, H=model.layers[2].H)\n",
        "print('BINARIZE_1')\n",
        "print(binary_kernel_1)\n",
        "# print('BINARIZE_2')\n",
        "# print(binary_kernel_2)\n",
        "# # print('BINARIZE_3')\n",
        "# # print(binary_kernel_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "G1m983Ljg1u4"
      },
      "outputs": [],
      "source": [
        "array_1 = binary_kernel_1.numpy()\n",
        "weight_file_1 = open('weight_1.txt', 'a')\n",
        "for i in range(len(binary_kernel_1)):\n",
        "  weight_file_1.write(str(array_1[i]) + '\\n')\n",
        "weight_file_1.close()\n",
        "\n",
        "# array_2 = binary_kernel_2.numpy() # 成功率若不夠再加\n",
        "# weight_file_2 = open('weight_2.txt', 'a')\n",
        "# for i in range(len(binary_kernel_2)):\n",
        "#   weight_file_2.write(str(array_2[i]) + '\\n')\n",
        "# weight_file_2.close()\n",
        "\n",
        "# array_3 = binary_kernel_3.numpy()\n",
        "# weight_file_1 = open('weight_3.txt', 'a')\n",
        "# for i in range(len(binary_kernel_3)):\n",
        "#   weight_file_1.write(str(array_1[i]) + '\\n')\n",
        "# weight_file_1.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdq6p-ss3aYr"
      },
      "outputs": [],
      "source": [
        "num = 0\n",
        "print('==============================1===========================')\n",
        "re_ker_1 = np.array([])\n",
        "for i in range(32):\n",
        "  num += 1\n",
        "  print(num)\n",
        "  print(array_1[:, :, 0, i])\n",
        "  re_ker_1 = np.append(re_ker_1, array_1[:, :, 0, i])\n",
        "print('==============================2===========================')\n",
        "kernel_array = re_ker_1.reshape(32, 9)# 成功率若不夠拿掉\n",
        "# re_ker_1 = re_ker_1.reshape(32, 9)# 成功率若不夠再加\n",
        "# print(re_ker_1)\n",
        "\n",
        "# print('==============================3===========================')\n",
        "# re_ker_2 = np.array([])# 成功率若不夠再加\n",
        "# for i in range(32):\n",
        "#   num += 1\n",
        "#   print(num)\n",
        "#   print(array_2[:, :, 0, i])\n",
        "#   re_ker_2 = np.append(re_ker_2, array_2[:, :, 0, i])\n",
        "# print('==============================4===========================')\n",
        "# re_ker_2 = re_ker_2.reshape(32, 9)\n",
        "# print(re_ker_2)\n",
        "# print('==============================5===========================')\n",
        "# kernel_array = np.append(re_ker_1, re_ker_2)\n",
        "# kernel_array = kernel_array.reshape(2, 32, 9)\n",
        "print(kernel_array)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BNN_0308.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
