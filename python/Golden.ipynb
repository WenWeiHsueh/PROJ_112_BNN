{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh0Inqmad5Y-",
        "outputId": "1eda02f9-cc2d-4d98-f68d-6e53ceb9e1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1 (BinaryConv2D)        (None, 32, 28, 28)        288       \n",
            "                                                                 \n",
            " pool2 (MaxPooling2D)        (None, 16, 14, 28)        0         \n",
            "                                                                 \n",
            " bn2 (BatchNormalization)    (None, 16, 14, 28)        64        \n",
            "                                                                 \n",
            " act2 (Activation)           (None, 16, 14, 28)        0         \n",
            "                                                                 \n",
            " act1 (Activation)           (None, 16, 14, 28)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                200736    \n",
            "                                                                 \n",
            " bn5 (BatchNormalization)    (None, 32)                128       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201,546\n",
            "Trainable params: 201,450\n",
            "Non-trainable params: 96\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1200/1200 [==============================] - 57s 47ms/step - loss: 0.9407 - accuracy: 0.9269 - val_loss: 0.9225 - val_accuracy: 0.9498\n",
            "Test score: 0.9224636554718018\n",
            "Test accuracy: 0.9498000144958496\n"
          ]
        }
      ],
      "source": [
        "'''Trains a simple binarize CNN on the MNIST dataset.\n",
        "Modified from keras' examples/mnist_mlp.py\n",
        "Gets to 98.98% test accuracy after 20 epochs using tensorflow backend\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.utils import np_utils\n",
        "from keras import callbacks\n",
        "from binary_ops import binary_tanh as binary_tanh_op\n",
        "from binary_layers import BinaryDense, BinaryConv2D\n",
        "from binary_ops import binarize\n",
        "from keras import callbacks\n",
        "def binary_tanh(x):\n",
        "    return binary_tanh_op(x)\n",
        "\n",
        "\n",
        "H = 1.\n",
        "kernel_lr_multiplier = 'Glorot'\n",
        "\n",
        "# nn\n",
        "batch_size = 50\n",
        "epochs = 20 \n",
        "channels = 1\n",
        "img_rows = 28 \n",
        "img_cols = 28 \n",
        "filters = 32 \n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2, 2)\n",
        "hidden_units = 128\n",
        "classes = 10\n",
        "use_bias = False\n",
        "#############################基本設定#############################\n",
        "# learning rate schedule\n",
        "lr_start = 1e-3\n",
        "lr_end = 1e-4\n",
        "lr_decay = (lr_end / lr_start)**(1. / epochs)\n",
        "\n",
        "# BN\n",
        "epsilon = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "# dropout\n",
        "p1 = 0.25\n",
        "p2 = 0.5\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(60000, 1, 28, 28) ####調整資料大小\n",
        "X_test = X_test.reshape(10000, 1, 28, 28)   ##調整資料大小\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255    ##正規化\n",
        "X_test /= 255     ##正規化\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, classes) * 2 - 1 # -1 or 1 for hinge loss\n",
        "Y_test = np_utils.to_categorical(y_test, classes) * 2 - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vOKdLENTgza-"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# conv1\n",
        "model.add(BinaryConv2D(32, kernel_size=kernel_size, input_shape=(channels, img_rows, img_cols),\n",
        "                       data_format='channels_first',\n",
        "                       H=H, kernel_lr_multiplier=kernel_lr_multiplier, \n",
        "                       padding='same', use_bias=use_bias, name='conv1'))\n",
        "model.add(BinaryConv2D(32, kernel_size=kernel_size, H=H, kernel_lr_multiplier=kernel_lr_multiplier,                         data_format='channels_first',\n",
        "                        padding='same', use_bias=use_bias, name='conv2'))\n",
        "model.add(BinaryConv2D(32, kernel_size=kernel_size, H=H, kernel_lr_multiplier=kernel_lr_multiplier,\n",
        "                        data_format='channels_first',\n",
        "                        padding='same', use_bias=use_bias, name='conv3'))\n",
        "model.add(MaxPooling2D(pool_size=pool_size, name='pool2', data_format='channels_last'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn2'))\n",
        "model.add(Activation(binary_tanh, name='act2'))\n",
        "#model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn1'))\n",
        "model.add(Activation(binary_tanh, name='act1'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "G1m983Ljg1u4"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn5'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "opt = Adam(lr=lr_start) \n",
        "model.compile(loss='squared_hinge', optimizer=opt, metrics=['accuracy'])\n",
        "model.summary()\n",
        "lr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay ** e)\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    batch_size=50, epochs=1,\n",
        "                    verbose=1, validation_data=(X_test, Y_test))\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(model.layers[0].get_weights())\n",
        "binary_kernel = binarize(model.layers[0].kernel, H=model.layers[0].H) \n",
        "binary_kernel_1 = binarize(model.layers[1].kernel, H=model.layers[1].H)\n",
        "print('BINARIZE_1')\n",
        "print(binary_kernel)\n",
        "print('BINARIZE_2')\n",
        "print(binary_kernel_1)\n",
        "\n",
        "array = binary_kernel.numpy()\n",
        "weight_file = open('weight_1.txt', 'a')\n",
        "for i in range(len(binary_kernel)):\n",
        "  weight_file.write(str(array[i]) + '\\n')\n",
        "weight_file.close()\n",
        "\n",
        "array_1 = binary_kernel_1.numpy()\n",
        "weight_file_1 = open('weight_2.txt', 'a')\n",
        "for i in range(len(binary_kernel_1)):\n",
        "  weight_file_1.write(str(array_1[i]) + '\\n')\n",
        "weight_file_1.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdq6p-ss3aYr"
      },
      "outputs": [],
      "source": [
        "num = 0\n",
        "print('==============================1===========================')\n",
        "re_ker_1 = np.array([])\n",
        "for i in range(32):\n",
        "  num += 1\n",
        "  print(num)\n",
        "  print(array[:, :, 0, i])\n",
        "  re_ker_1 = np.append(re_ker_1, array[:, :, 0, i])\n",
        "print('==============================2===========================')\n",
        "kernel_array = re_ker_1.reshape(32, 9)# 成功率若不夠拿掉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EJi-egZfUQo",
        "outputId": "200bbd81-300a-481e-ff13-9457c647ebac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "''' 從google drive內讀檔 '''\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive') # 第一次執行時需要驗證碼，照著指示做就行了\n",
        "# os.mkdir('/content/drive/MyDrive/Mnist') # 請確認你的google drive內有 'Mnist' 資料夾，沒有就用這個創一個\n",
        "# os.mkdir('/content/drive/MyDrive/Mnist/K1') # 請確認你的google drive內有 'Mnist/K1' 資料夾，沒有就用這個創一個\n",
        "# os.mkdir('/content/drive/MyDrive/Mnist/K2') # 請確認你的google drive內有 'Mnist/K2' 資料夾，沒有就用這個創一個\n",
        "path = '/content/drive/MyDrive/Mnist/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "4Vg74_NpfVHJ",
        "outputId": "97abca41-548c-4587-ffc7-196f0ba3257d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 1\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    \n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print_index = 0\n",
        "plt.imshow(np.reshape(x_train[print_index], (28, 28)), cmap='gray')  \n",
        "plt.title('%i' % y_train[print_index])  \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tUwK4JdVfWef"
      },
      "outputs": [],
      "source": [
        "def float_to_hex(data, int_bit, point_bit, merge):\n",
        "  hex_map = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F']\n",
        "\n",
        "  int_part = data - data % 1 # 整數部分\n",
        "  point_part = data % 1 # 小數部分\n",
        "  bit_num = int_bit + point_bit # 總bit數\n",
        "  bit_res = bit_num % 4 # 處理到最後剩餘bit數\n",
        "  before_merge = ['' for data_num in range(len(data))] # 合併前結果\n",
        "\n",
        "  for data_index in range(len(data)): # 將signed轉換成unsigned\n",
        "    if int_part[data_index] < 0:\n",
        "      int_part[data_index] += (2 ** int_bit)\n",
        "\n",
        "  unsigned_fixed = int_part + point_part # unsigned fixed point //用unsigned 的方式把signed 數字的bit formate表示出來\n",
        "  for pow in range(int_bit, -point_bit - 1, -4):\n",
        "    if pow != int_bit:\n",
        "      unsigned_fixed = unsigned_fixed * (2 ** -pow)\n",
        "      for data_index in range(len(unsigned_fixed)):\n",
        "        before_merge[data_index] = before_merge[data_index] + hex_map[int(unsigned_fixed[data_index])]\n",
        "      unsigned_fixed = (unsigned_fixed % 1) * (2 ** pow)\n",
        "  if bit_res != 0: # 剩餘bit\n",
        "    unsigned_fixed = (unsigned_fixed * (2 ** point_bit) - (unsigned_fixed * (2 ** point_bit) % 1)) * (2 ** (4 - bit_res))\n",
        "    for data_index in range(len(unsigned_fixed)):\n",
        "      before_merge[data_index] = before_merge[data_index] + hex_map[int(unsigned_fixed[data_index])]\n",
        "\n",
        "  #print(before_merge)\n",
        "\n",
        "  if len(data) % merge != 0:\n",
        "    print('無法整除')\n",
        "  else:\n",
        "    result = ['' for data_num in range(int(len(data) / merge))] # Merge後結果\n",
        "\n",
        "    head_index = 0 # 開頭位置\n",
        "    now_index = 0 # 儲存在result的位置\n",
        "\n",
        "    while now_index != len(result):\n",
        "      for i in range(head_index, head_index + merge):\n",
        "        result[now_index] += before_merge[i]\n",
        "      head_index += merge\n",
        "      now_index += 1\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = np.array([-1.5 , -2.75 , -3.5 , -4.25 , 2.75 , 1.85 , 5.0 , 4.25 ])\n",
        "result = float_to_hex(data,3,5,4)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "e7GiXHqlfYov"
      },
      "outputs": [],
      "source": [
        "def Golden(image, kernel, num_kernel):\n",
        "\n",
        "  Conv_weight = np.array(kernel[num_kernel])\n",
        "  Conv_weight = Conv_weight - Conv_weight % (2 ** -5)\n",
        "  row_kernel = np.array([]) # temp for every row output form Conv kernel 1\n",
        "  '''To MaxPool'''\n",
        "  Imageout_kernal = np.empty((0, 26), float) # Image output form kernal 1\n",
        "  ################\n",
        "\n",
        "  for col in range(0,26):\n",
        "    for row in range(0,26):\n",
        "      filter = 0\n",
        "      for i in range(0,3,1):\n",
        "        for j in range(0,3,1):\n",
        "          tmp1 = image[col + i, row + j] * Conv_weight[3 * i + j]\n",
        "          filter += tmp1\n",
        "      if filter % (2 ** -5) >= (2 ** -6):\n",
        "        filter += (2 ** -5)\n",
        "      #filter = max(filter, 0)\n",
        "      row_kernel = np.append(row_kernel, filter)\n",
        "    Imageout_kernal = np.append(Imageout_kernal, np.expand_dims(row_kernel, axis = 0), axis = 0)\n",
        "    row_kernel = np.array([])\n",
        "\n",
        "  #print(np.reshape((Imageout_kernal_1), 676))\n",
        "  #print(np.reshape((Imageout_kernal_2), 676))\n",
        "  \n",
        "  result = float_to_hex(np.reshape((Imageout_kernal), 676), 3, 5, 26)\n",
        "  print(result)\n",
        "  print(1)\n",
        "  output_file_name = 'test_' + '0' + '_kernel_' + str(num_kernel) + '_hex.txt'\n",
        "  output_file = open(output_file_name, 'w')\n",
        "  for data in result:\n",
        "    output_file.write(data + '\\n')\n",
        "  output_file.close()\n",
        "\n",
        "  '''for index in range(len(result1)):\n",
        "      if np.reshape((Imageout_kernal_1), 676)[index] - np.reshape((Imageout_kernal_1), 676)[index] % (2 ** -5) != int(result1[index][0], 16) * (2 ** -1) + int(result1[index][1], 16) * (2 ** -5):\n",
        "        print(\"hi1 : \", index)\n",
        "        print( np.reshape((Imageout_kernal_1), 676)[index] - np.reshape((Imageout_kernal_1), 676)[index] % (2 ** -5), int(result1[index][0], 16) * (2 ** -1) + int(result1[index][1], 16) * (2 ** -5))\n",
        "  for index in range(len(result2)):\n",
        "      if np.reshape((Imageout_kernal_2), 676)[index] - np.reshape((Imageout_kernal_2), 676)[index] % (2 ** -5) != int(result2[index][0], 16) * (2 ** -1) + int(result2[index][1], 16) * (2 ** -5):\n",
        "        print(\"hi2\", index)\n",
        "           print( np.reshape((Imageout_kernal_2), 676)[index] - np.reshape((Imageout_kernal_2), 676)[index] % (2 ** -5), int(result2[index][0], 16) * (2 ** -1) + int(result2[index][1], 16) * (2 ** -5))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PGD5dRfQvQwi"
      },
      "outputs": [],
      "source": [
        "#print(x_train[print_index] - x_train[print_index] % (2 ** -5))\n",
        "plt.imshow(np.reshape(x_train[print_index], (28, 28)), cmap='gray')\n",
        "plt.title('%i' % y_train[print_index])  \n",
        "plt.show()\n",
        "print('layer_0')\n",
        "for num_kernel in range(0, 32):\n",
        "  Golden(np.reshape(x_train[0] - x_train[0] % (2 ** -5), (28, 28)), kernel_array, num_kernel)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BNN_0308.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
